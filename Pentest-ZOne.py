#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
 _____        _____    _____          _____  ____
| ___ \      |_   _|  /  ___| |      |___  /  _  |           
| |_/ /__ _ __ | | ___\ `--.| |_ ______ / /| | | |_ __   ___ 
|  __/ _ \ '_ \| |/ _ \`--. \ __|______/ / | | | | '_ \ / _ \
| | |  __/ | | | |  __/\__/ / |_     ./ /__\ \_/ / | | |  __/
\_|  \___|_| |_\_/\___\____/ \__|    \_____/\___/|_| |_|\___|
                                                          
OFFICIAL WEB SECURITY SCANNER
'''
#Hello KeyStrOke it's Time to Scan Some Servers Let The Work Begin
#-----------------------------
import string
import random
maxURL = 100
SQLI = ["'", '"', "')", ")", '")']
LogicSQLI = [" AND 1=1", "+order+by+1"]
comments = ["--", "--+", "#", "--+-", ";%00", "`"]
crosstest = ["<font color=red>KeyStrOke</font>", "<script>alert(1)</script>"]
#-----------------------------
urlist = []
patternslist = ["href='(.*?)'", 'href="(.*?)"', "src='(.*?)'", 'src="(.*?)"', "javascript:(.*?)"]
maxLisT = 10000
#-----------------------------
def uniqueit(item):
    try:
        if(item not in urlist):
            urlist.append(item)       		
    except :
        pass
def uniques(seq):
    seen = set()
    return [seen.add(x) or x for x in seq if x not in seen]
def checkblacklisted(item):
    try:
        for it in urlist :
            if(item in it):
                return False			
    except :
        pass
def checkfolder(item):
    try:
        fpattern = item[0]
        if(fpattern == "/"):
            return True
    except :
        pass
def GetHost(url):
    try:
        patt = "://(.*?)/"
        hosts = re.findall(patt, url)
        if("https://" in url):
            return "https://"+hosts[0]+"/"
        else :
            return "http://"+hosts[0]+"/"
    except :
        pass
def mainpath(url):
    try:
        fullpa = os.path.dirname(url)
        return fullpa+"/"		
    except :
        pass
def basebath(url):
    try:
        basenm = os.path.basename(url)
        return basenm
    except :
        pass
def checkifparam(url):
    try:
        flp = url[0]
        if(flp == "?"):
            return True		
    except :
        pass
def webcrawler(url):
   try:
            data = urllib2.urlopen(url).read()
            for pattern in patternslist :
                crawled = re.findall(pattern, data)
                for i in crawled :
                    if("http" in i):
                        if(FiltIT(i)):
                            uniqueit(i)
                    else :
                        if("?" in url):
                            urls = url.split("?")					
                            urls = urls[0]				
                            if(FiltIT(i)):	
                                if(checkfolder(i)):									
                                    mhos = mainpath(url)																						
                                    uniqueit(mhos+i)						
                                elif(checkifparam(url)):
                                    print "xD"                                                                  					
                                else :						
                                    mhos = mainpath(url)						
                                    uniqueit(mhos+i)										
                        else :
                            if(FiltIT(i)):				
                                if checkfolder(i):					
                                    mhos = mainpath(url)					
                                    uniqueit(mhos+i)
                                elif(checkifparam(url)):
                                    print "xD" 									
                                else:					
                                    mhos = mainpath(url)					
                                    uniqueit(mhos+i)					
   except:
        pass
def MassWebCrawler():
    try:
        for urlit in urlist :
            if(len(uniques(urlist)) <= maxLisT):
                webcrawler(urlit)		
    except :
        pass
def IsQLI(data):
    if "You have an error in your SQL" in data:
       return 1;
    elif "supplied argument is not a valid MySQL result resource in" in data:
       return 1;
    elif "Division by zero in" in data:
       return 1;
    elif "Microsoft JET Database" in data:
       return 1;
    elif "Microsoft OLE DB Provider for SQL Server" in data:
       return 1;
    elif "ODBC Microsoft Access Driver" in data:
       return 1;
    elif "Unclosed quotation mark" in data:
       return 1;
    elif "Microsoft OLE DB Provider for Oracle" in data:
       return 1;
    elif "Incorrect syntax near" in data:
       return 1;
    elif "SQL query failed" in data:
       return 1;
    return 0;
def grabParameters(url):
    try:
        patternone = "&(.*?)="
        patterntwo = "(.*?)=(.*?)&"
        parameterso = re.findall(patternone, url)
        parameterst = re.findall(patterntwo, url)
        neededparam = parameterst[0]
        theone = neededparam[0].split("?")[1]
        parameters = parameterso
        parameters.append(theone)
        return parameters
    except :
	    pass
def setparametere(url, parameter, data):
    try:
        main = "?"+str(parameter)+"="
        if(main in url):
            patternv = str(parameter)+"=(.*?)&"
            value = re.findall(patternv, url)
            requested = value[0]	
            fullrequest = str(parameter)+"="+str(requested)	
            therequest = str(parameter)+"="+str(requested)+str(data)	
            myrequest = url.replace(fullrequest, therequest)
            return myrequest
        else :
            url = url + "&KeyStrOkemainscanner=1"
            patternv = str(parameter)+"=(.*?)&"
            value = re.findall(patternv, url)
            requested = value[0]	
            fullrequest = str(parameter)+"="+str(requested)	
            therequest = str(parameter)+"="+str(requested)+str(data)	
            myrequest = url.replace(fullrequest, therequest)
            return myrequest
    except :
        pass
def BlindSQLI(clear, injected, error):
    try:
	    if(clear != injected):
                return True
            else:
                return False
    except :
        pass
def ConfirmSQLI(url, error, normal, parameter):
    try:
        if(parameter == ""):
            for logic in LogicSQLI :
	            checkR = urllib2.urlopen(url + logic).read()
                    if(checkR == normal):
                        print "SQL INJECTION CONFIRMED (1)" + str(logic)
                        break
                    else :
                        for comment in comments :
                            checkC = urllib2.urlopen(url + logic + comment).read()
                            if(checkC == normal):
                                print "SQL INJECTION CONFIRMED (2)"
                            else :
                                checkT = urllib2.urlopen(url + "'" + logic + comment).read()
                                if(checkT == normal):
                                    print "SQL INJECTION CONFIRMED (3)"
                                    break
                                else :
			                        print "Probably SQLI : (check it manually)"
			                        break
			print "Done"
        else :
            for logic in LogicSQLI :
			   MainURL = setparametere(url, parameter, logic).replace(" ", "%20")
			   checkR = urllib2.urlopen(MainURL).read() 
			   if(checkR == normal): 
			       print "SQL INJECTION CONFIRMED (1)" + str(logic) + " : " + str(parameter)
			       break
			   else : 
			        for comment in comments : 
			            checkC = urllib2.urlopen(url + logic + comment).read()
			            if(checkC == normal):
			                print "SQL INJECTION CONFIRMED (2)" + " : " + str(parameter)
                                        break
			            else :
			                checkT = urllib2.urlopen(url + "'" + logic + comment).read()
			                if(checkT == normal):
			                    print "SQL INJECTION CONFIRMED (3)" + " : " + str(parameter)
			                    break
			                else :
			                    print "Probably SQLI : (check it manually)" + " : " + str(parameter)
			                    break
    except :
        pass
def GetInputs(host):
    try:
        inputs = []	
        content = urllib2.urlopen(host).readlines()	
        for line in content :
            if("<input" in line):
                pattern = 'name="(.*?)"'
                names = re.findall(pattern, line)
                if(len(names) > 0):
                    for name in names :
			            inputs.append(name)
                patterns = "name='(.*?)'"
                nmes = re.findall(patterns, line)
                if(len(nmes) > 0):
                    for nm in nmes :
                        inputs.append(nm)
        return inputs   
    except :
        pass	
def postvalue(size=6, chars=string.ascii_uppercase):
    return ''.join(random.choice(chars) for _ in range(size))
def BlindPOST(normal, injected):
    try:
        if(normal != injected):
            return True
    except :
        pass
def PostSQLI(url, params, nrequest):
    try :
        httreq = urllib2.Request(url, params)	
        httresp = urllib2.urlopen(httreq)	
        httpage = httresp.read()
        if(IsQLI(httpage)):
            return True
        else :
            noreq = urllib2.Request(url, nrequest)	
            getreq = urllib2.urlopen(noreq)	
            readre = getreq.read()
            if(BlindPOST(readre, httpage)):            
                return True         
    except :
       pass
def PostIT(url, parameters):
    try:
        request = {}
        if(len(parameters) > 0):
            if(len(parameters) == 1):
                for inp in parameters :
                    request[inp] = postvalue()				
            else :
                for inps in parameters :
                    request[inps] = postvalue()
        url_param = urllib.urlencode(request)
        for paramx in parameters :
            for tests in SQLI :
                tests = tests.replace(" ", "+")
                injected_req = setparametere(url_param, paramx, tests).replace("&KeyStrOkemainscanner=1", "")
                PostSQLI(url, injected_req, url_param)
                if PostSQLI(url, injected_req, url_param):
                    print "Sql Injection : " + tests
    except :
        pass
def ScanSQLI(url):
    try:
        # Testing Using GET parameter
        if("?" in url):
            if("&" not in url):
                for tests in SQLI :
                    htmlResult = urllib2.urlopen(url + tests).read()
                    clearResult = urllib2.urlopen(url).read()
                    errorResult = urllib2.urlopen(url + "KeyStrOke").read()
                    if(IsQLI(htmlResult)):
                        ConfirmSQLI(url, errorResult, clearResult, "")
                        break
                    elif(BlindSQLI(clearResult, htmlResult, errorResult, "")) :
                        ConfirmSQLI(url, errorResult, clearResult)
                        break
            else :
                for parameter in grabParameters(url):
                     for tests in SQLI :
                        currentURL = setparametere(url, parameter, tests).replace(" ", "%20")
                        htmlResult = urllib2.urlopen(currentURL).read()
                        clearResult = urllib2.urlopen(url).read()
                        errorURL = setparametere(url, parameter, "KeyStrOke").replace(" ", "%20")
                        errorResult = urllib2.urlopen(url + errorURL).read()
                        if(IsQLI(htmlResult)):
                            ConfirmSQLI(url, errorResult, clearResult, parameter)
                            break
                        elif(BlindSQLI(clearResult, htmlResult, errorResult)) :
                            ConfirmSQLI(url, errorResult, clearResult, parameter)
                            break
        #Testing Using POST method
        else:
            inputlist = GetInputs(url)
            PostIT(url, inputlist)
    except :
        pass
def GetLog(url):
   try :
       url = url.replace("/", "") 
       url = url.replace(".", "") 
       if("https" in url):
           url = url.replace("http", "") 
       elif("http" in url):
           url = url.replace("https", "") 
       url = url.replace(":", "") 
       url = url.replace("www", "") 
       logfile = url + "_report.json"
       return logfile 
   except :
      pass
def unique(seq):
    seen = set()
    return [seen.add(x) or x for x in seq if x not in seen]
def FilterSpecial(url):
    try :
        if("facebook.com" in url):
            return False
        elif("twitter.com" in url):
            return False
        else :
            return True
    except :
       pass
def makeitunique(item):
    try:
        if(item not in links):
            return True		
    except :
	    pass
def crawler(url):
    try :
        links.append(url)
        for i in re.findall('''href=["'](?!javascript:)(.[^"']+)["']''', urllib.urlopen(url).read(), re.I):
                check = re.match('(?!http|ftp)', i);
                if(check):
                    if("?" in url):
                        urls = url.split("?")
                        urls = urls[0]
                        i = urls + i
                    else :
                        i = url+i
                if(FiltIT(i)):
                        links.append(i)
    except :
	    pass
def MassCrawler():
    try:
       i = 0
       for url in links :
                if(i <= maxURL):
                      if(FiltIT(url)):
                          crawler(url)
                          i = i + 1
                else:
                      break
    except :
        pass
def LogVuln(vuln, url):
    try:
	    for url in unique(links) :
             log.write(vuln+":"+url +'\n')
    except:
        pass
def FiltIT(url):
    try:
        if("facebook.com" in url):
            return False
        elif("twitter.com" in url):
            return False
        elif("pinterest.com" in url):
            return False
        elif("youtube.com" in url):
            return False
        elif("google.com" in url):
            return False
        else :
            return True		
    except :
        pass
def IsLFI(content):
    try:
	    if("Warning: include" in content):
             return True
            elif("Warning:" in content) :
             return True
            elif("include" in content):
             return True
            elif("No such file" in content):
             return True
            elif("No such file or directory in" in content):
             return True
            elif("failed to open stream" in content):
             return True
            else:
		     return False
    except :
        pass
def ConfirmLFI(url, parameter):
        dirt = ""
        trunc = ""
        if(parameter == ""):
            dirtraverse = "../"
            truncations = ["/."]
            dirs = "etc/passwd"
            i = 0
            nonparam = url.split("=")
            nonvalue = nonparam[0]+"="
            checker = urllib2.urlopen(nonvalue + "/" + str(dirs)).read()
            if("root:" in checker):
                print "LFI Confirmed  : Root"
            else :
                while(i < 30):
                    dirt = dirt + dirtraverse
                    data = urllib2.urlopen(nonvalue+dirt+dirs).read()
                    if("root:" in checker):
                        print "LFI Confirmed  : Dirs"
                        break
                    else:
					    datas = urllib2.urlopen(nonvalue+dirt+dirs+"%00").read()
					    if("root:" in checker):
                                                 print "LFI Confirmed  : Trunc"
                                                 break
                                            else:
                                                 for trun in truncations :
                                                     a = 0
                                                     while(a<100):
                                                         trunc = trunc + trun
                                                         dta = urllib2.urlopen(nonvalue+dirt+dirs+trunc)
                                                         if("root:" in dta):
                                                             print "Truncated : LFI"
                                                             break
                                                         else :
                                                             a = a + 1
                                                     trun = ""
                    i = i + 1
        else:
            pass		
def ScanLFI(url):
        if("?" in url):
            if("&" not in url):
               prefix = "KeyStrOkemainscanner.php"
               data = urllib2.urlopen(url + prefix).read()
               if(IsLFI(data)):
                   print "Probably LFI : Checking Automatically"
                   ConfirmLFI(url, "")
            else:
                pass
        else :
            pass
def PostXSS(url, params, xsstest):
    try:
        httreq = urllib2.Request(url, params)	
        httresp = urllib2.urlopen(httreq)	
        httpage = httresp.read()
        if(xsstest in httpage):
            return True       
    except :
	    pass
def XSSIT(url, parameters):
    try:
        request = {}
        if(len(parameters) > 0):
            if(len(parameters) == 1):
                for inp in parameters :
                    request[inp] = postvalue()				
            else :
                for inps in parameters :
                    request[inps] = postvalue()
        url_param = urllib.urlencode(request)
        for paramx in parameters :
            for tests in crosstest :
                tests = tests.replace(" ", "%20")
                injected_req = setparametere(url_param, paramx, tests).replace("&KeyStrOkemainscanner=1", "")
                ntest = tests.replace("%20", " ")
                if PostXSS(url, injected_req, ntest):
                    print "Cross Site Scripting : " + tests
    except :
        pass	
def ScanXSS(url):
    try:
	    if("?" in url):
                if("&" not in url):
                    for tests in crosstest :
                        tests = tests.replace(" ", "%20")
                        crossdata = urllib2.urlopen(url + tests).read()
                        if(tests in crossdata):
                            print "Cross Site Scripting : 1"					
                else :
                    for parameter in grabParameters(url):	
                        for test in crosstest :
                            test = test.replace(" ", "%20")						
                            injectedRI = setparametere(url, parameter, test).replace(" ", "%20")												
                            mainDT = urllib2.urlopen(injectedRI).read()						
                            if(test in mainDT):						
                                print "Cross Site Scripting : 2 " + str(url)					
	    else :
                inputlist = GetInputs(url)
                XSSIT(url, inputlist)
    except :
	    pass
def ScanIT(url):
    try:
        ScanSQLI(url)
        ScanLFI(url)
        ScanXSS(url)
    except :
        pass
#-----------------------------
import urllib2
import urllib
import re
import sys
import datetime
import string
import random
import os
import json
links = []
sqlInjection = []
lfi = []
xss = []
try:
    theurl = sys.argv[1]
except:
     print "No url specified, exiting ..."
     sys.exit()
thelog = GetLog(theurl)
log = open("reports/"+thelog ,'w+')
webcrawler(theurl)
MassWebCrawler()
for url in unique(urlist) :
    print url
    ScanIT(url)
    LogVuln("", url)